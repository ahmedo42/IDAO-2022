{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xf dichalcogenides_private.tar.gz\n",
    "!tar -xf dichalcogenides_public.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T11:45:40.935045Z",
     "iopub.status.busy": "2022-02-21T11:45:40.934775Z",
     "iopub.status.idle": "2022-02-21T11:45:45.296618Z",
     "shell.execute_reply": "2022-02-21T11:45:45.295841Z",
     "shell.execute_reply.started": "2022-02-21T11:45:40.935008Z"
    },
    "id": "bp9bALmUHNVL"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import json\n",
    "from pymatgen.core import Structure\n",
    "\n",
    "def read_pymatgen_dict(file):\n",
    "    with open(file, \"r\") as f:\n",
    "        d = json.load(f)\n",
    "    return Structure.from_dict(d)\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T11:47:55.39352Z",
     "iopub.status.busy": "2022-02-21T11:47:55.392986Z",
     "iopub.status.idle": "2022-02-21T15:27:46.562991Z",
     "shell.execute_reply": "2022-02-21T15:27:46.469648Z",
     "shell.execute_reply.started": "2022-02-21T11:47:55.393482Z"
    },
    "id": "jObWgMjhHW8t",
    "outputId": "87b5c05e-cb53-4d1e-b7a8-2f649a03206b"
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "import json\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import argparse\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from megnet.models import MEGNetModel\n",
    "from megnet.data.crystal import CrystalGraph\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.metrics import MeanAbsoluteError\n",
    "\n",
    "train_datapath = \"dichalcogenides_public\"\n",
    "\n",
    "config = {\n",
    "    \"seed\" : 17,\n",
    "    \"epochs\" :800,\n",
    "    \"batch_size\":128,\n",
    "    \"lr\":0.001,\n",
    "    \"cutoff\":4.0,\n",
    "    \"nblocks\":3,\n",
    "    \"npass\":2,\n",
    "    \"width\":0.5,\n",
    "    \"nfeat_bond\":100,\n",
    "    \"embedding_dim\":16,\n",
    "    \"additional_data\":False,\n",
    "    \"test_size\":0.20,\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "checkpoint_filepath = \"./checkpoint\"\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor=\"ewt\",\n",
    "    mode=\"max\",\n",
    "    save_best_only=True)\n",
    "\n",
    "reduce_lr_callback = ReduceLROnPlateau(monitor=\"mean_absolute_error\",mode=\"min\", factor=0.2,patience=30, min_lr=0.00001,verbose=1)\n",
    "\n",
    "\n",
    "def ewt(prediction, target):\n",
    "    # compute absolute error on energy per system.\n",
    "    # then count the no. of systems where max energy error is < 0.02.\n",
    "    e_thresh = 0.02\n",
    "    error_energy = tf.math.abs(target - prediction)\n",
    "\n",
    "    success = tf.math.count_nonzero(error_energy < e_thresh)\n",
    "    total = tf.size(target)\n",
    "    return success / tf.cast(total, tf.int64)\n",
    "\n",
    "def prepare_dataset(config):\n",
    "    dataset_path = Path(train_datapath)\n",
    "    targets = pd.read_csv(dataset_path / \"targets.csv\", index_col=0)\n",
    "    struct = {\n",
    "        item.name.strip(\".json\"): read_pymatgen_dict(item)\n",
    "        for item in (dataset_path / \"structures\").iterdir()\n",
    "    }\n",
    "\n",
    "    data = pd.DataFrame(columns=[\"structures\"], index=struct.keys())\n",
    "    data = data.assign(structures=struct.values(), targets=targets)\n",
    "\n",
    "    return data\n",
    "\n",
    " \n",
    "def prepare_model(config):\n",
    "    nfeat_bond = config[\"nfeat_bond\"]\n",
    "    r_cutoff = config[\"cutoff\"]\n",
    "    gaussian_centers = np.linspace(0, r_cutoff + 1, nfeat_bond)\n",
    "    gaussian_width = config[\"width\"]\n",
    "\n",
    "    pretrained_model = MEGNetModel.from_file(\"band_gap_regression.hdf5\")\n",
    "    model = MEGNetModel(\n",
    "        graph_converter=CrystalGraph(cutoff=r_cutoff),\n",
    "        centers=gaussian_centers,\n",
    "        width=gaussian_width,\n",
    "        nblocks=config[\"nblocks\"],\n",
    "        loss=[\"MAE\"],\n",
    "        npass=config[\"npass\"],\n",
    "        lr=config[\"lr\"],\n",
    "        embedding_dim=config[\"embedding_dim\"],\n",
    "        metrics=[ewt,tf.keras.metrics.MeanAbsoluteError()])\n",
    "    weights = pretrained_model.get_weights()\n",
    "    model.set_weights(weights) \n",
    "    #embedding_layer_index = [i for i, j in enumerate(model.layers) if j.name.startswith('atom_embedding')][0]\n",
    "    #model.layers[embedding_layer_index].trainable = False\n",
    "\n",
    "    return model\n",
    "\n",
    "def main(config):\n",
    "    seed_everything(config[\"seed\"])\n",
    "    train = prepare_dataset(config)\n",
    "    model = prepare_model(config)\n",
    "    model.train(\n",
    "        train.structures,\n",
    "        train.targets,\n",
    "        epochs=config[\"epochs\"],\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        callbacks=[model_checkpoint_callback,reduce_lr_callback],\n",
    "        save_checkpoint=False,\n",
    "    )\n",
    "\n",
    "\n",
    "with open(\"config.json\", 'w') as f:\n",
    "    json.dump(config, f, indent=4)\n",
    "main(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T15:27:51.351446Z",
     "iopub.status.busy": "2022-02-21T15:27:51.351171Z",
     "iopub.status.idle": "2022-02-21T15:30:11.510909Z",
     "shell.execute_reply": "2022-02-21T15:30:11.510131Z",
     "shell.execute_reply.started": "2022-02-21T15:27:51.351415Z"
    },
    "id": "1kvg8IkILmox",
    "outputId": "ddd66c87-7c32-407d-f608-124d71befd9a"
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "\n",
    "checkpoint_path = \"./checkpoint\"\n",
    "test_datapath = \"dichalcogenides_private\"\n",
    "\n",
    "def submit(config):\n",
    "    model = prepare_model(config)\n",
    "    model.load_weights(checkpoint_path)\n",
    "\n",
    "    dataset_path = Path(test_datapath)\n",
    "    struct = {item.name.strip('.json'): read_pymatgen_dict(item) for item in (dataset_path/'structures').iterdir()}\n",
    "    private_test = pd.DataFrame(columns=['id', 'structures'], index=struct.keys())\n",
    "    private_test = private_test.assign(structures=struct.values())\n",
    "    private_test = private_test.assign(predictions=model.predict_structures(private_test.structures))\n",
    "    private_test[['predictions']].to_csv('./submission.csv', index_label='id')\n",
    "\n",
    "with open(\"config.json\") as f:\n",
    "    config = json.loads(f.read())\n",
    "submit(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
